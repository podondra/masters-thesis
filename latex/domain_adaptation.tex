\chapter{Domain Adaptation}
\label{da_chapter}

In this chapter, we survey the current state of domain adaptation using neural network models
in the context of the machine and transfer learning.
We formally define the domain adaptation scenario
and categorise it according to recent surveys
by Wang and Deng~\cite{wang2018} and Csurka~\cite{csurka2017}.
From each category, we select a representative method for our experiments.
Then, we introduce in detail selected methods.
We conclude the chapter with applications of domain adaptation in astronomy.

\section{Domain Adaptation in the Context of Machine Learning}

Domain adaptation is a subfield of transfer learning,
which is part of machine learning.
Machine learning has a common assumption that training and test data are
\textit{independent and identically distributed} (IID)
that means data are drawn from the same feature space and the same distribution.~\cite{daume2006}
When this assumption does not hold transfer learning or domain adaptation come into play.
Moreover, from the biological point of the assumption seems to limit
because humans seem to have natural ways to transfer knowledge from previous experience to new challenges.~\cite{torrey2010}

Transfer learning is defined in most papers regarding the survey by Pan and Yang~\cite{pan2010}.
However, there is a more recent survey by Weiss et al.~\cite{weiss2016}
that has the benefit of containing newer methods than the survey by Pan and Yang~\cite{pan2010}.
However, its definition of transfer learning and domain adaptation is the same.

Pan and Yang~\cite{pan2010} define transfer learning
as the ability of a system to recognise and apply knowledge and skill
learned in previous problems to novel problems,
and they introduce the notion of a \textit{domain} and a \textit{task}.

A domain consists of a \textit{feature space} \(X\) and a marginal probability distribution \(P(X)\)
(marginal express that it is summed over a label space \(Y\)).
Therefore, a domain is as a tuple \(\mathcal{D} = [X, P(X)]\)
of a~\(d\)-dimensional feature space \(X \subset \mathbb{R}^d\)
and a~marginal probability distribution \(P(X)\).

Given a specific domain \(\mathcal{D}\),
a task consists of a \textit{label space} and an \textit{objective predictive function}
which is not observed but learned from training data.
Therefore, a task is also defined a tuple \(\mathcal{T} = [Y, P(Y | X)]\)
where \(Y\) is a label space
and \(P(Y | X)\) a conditional probability distribution
which we like to model as closely as possible.

When we are given a transfer learning problem,
we have to identify a source domain and a source learning task,
a target domain and a target learning task.
Then, transfer learning aims to help improve the learning of the target predictive function in the target domain
using knowledge from the source domain and the source task,
where the domains are different or the tasks are different.
As we will see, domain adaptation is the case
when the source and target domains are different,
while the source and target tasks are the same.~\cite{pan2010}

\begin{figure}
\begin{center}
\tikzstyle{dom} = [circle, draw=black, align=center]
\begin{tikzpicture}[node distance=4cm]
	\node (src) [dom] {source\\domain};
	\node (trg) [dom, right of=src] {target\\domain};
	\node (knowledge) [ellipse, draw=black, below of=src] {knowledge};
	\node (model) [rectangle, draw=black, align=center, below of=trg] {learning\\system};
	\draw [->] (src) -- (knowledge);
	\draw [->] (knowledge) -- (model);
	\draw [->] (trg) -- (model);
\end{tikzpicture}
\end{center}
\caption[Schematic depiction of domain adaptation]{
	Schematic diagram of domain adaptation depicts the fundamental intuition behind it.
	A domain adaptation model has to extract as much knowledge as possible from the source domain,
	and apply it to the target data.
	}
\end{figure}

For example, we have introduced in previous Chapter~\ref{data_chapter}
two domains.
The source domain is the SDSS DR14 and the LAMOST DR5 is the target domain.
We have shown that the domain have different data distribution
mainly because of their targeting strategies and instruments.
The task to identify QSOs is the same for both SDSS DR14 and LAMOST DR5
as we defined it.

Lastly, Torrey and Shavlik in~\cite{torrey2010} warn
that sometimes transfer learning can be harmful.
Performance of our machine learning algorithm might suffer
when the source and target domains or tasks need to be sufficiently related
else negative transfer may occur.
When the usage of source data degrades the performance,
the situation is called \textit{negative transfer}.
On the other side, when the performance is improved,
we talk about a \textit{positive transfer}.

\section{Theory and Formalization of Domain Adaptation}

Now, we introduce the crucial concept of our work: \textit{domain adaptation} (DA).
DA is a particular case of transfer learning
that leverages data from the source domain to learn a classifier for a target domain while the tasks are the same.
It is assumed that source and target domains are not identical but related.
If the domains were identical, it would be a standard machine learning problem.
Therefore, there is a distribution discrepancy between the source and target domains.~\cite{csurka2017}

More formally DA is the scenario of transfer learning
when the source \(\mathcal{D}^s = [X^s, P(X^s)]\)
and target \(\mathcal{D}^t = [X^t, P(X^t)]\) domains
are different (\(\mathcal{D}^s \ne \mathcal{D}^t\)),
but the source \(\mathcal{T}^s\) and target \(\mathcal{T}^t\)
tasks are the same (\(\mathcal{T}^s = \mathcal{T}^t\)).
The first condition implies
that \(X^s \ne X^t\), \(P(X^s) \ne P(X^t)\) or both are true.~\cite{pan2010}
In our case, the domains are different
because the two archives have different target selection strategies,
and the instruments are different (see Section~\ref{large_spec_surveys}).

Based on the condition \(\mathcal{D}^s \ne \mathcal{D}^t\)
we categorise DA into \textit{homogeneous} and \textit{heterogeneous}.
Homogeneous DA is setting in which the source \(X^s\)
and target \(X^t\) feature spaces are the same (\(X^s = X^t\))
while in \textit{heterogeneous} DA, the source and target spaces are different
(\(X^s \ne X^t\)).~\cite{csurka2017}

Our case is the homogeneous DA,
where the feature spaces are identical (\(X^s = X^t\)).
Still, the source and target data have different distributions (\(P(X^s) \ne P(X^t)\)).
Therefore, further, we focus on homogeneous DA
because our spectra can be prepared into the same feature space \(\mathbb{R}^{3659}\)
(see Section~\ref{data_preparation}).

The second categorisation of DA is according to availability of labels in the target domain.
Wang and Deng~\cite{wang2018} distinguish \textit{supervised}, \textit{semi-supervised} and \textit{unsupervised} DA:

\begin{itemize}
	\item supervised DA: labelled data in the target domain are present;
	\item semi-supervised DA: we have only a minimal amount of labelled data in the target domain while most of the data is unlabelled;
	\item unsupervised DA: no labelled data are available in the target domain.
\end{itemize}

We phrase our problem as \textit{unsupervised DA}
because the LAMOST survey uses different criteria for identification of QSOs than SDSS
(see Section~\ref{large_spec_surveys}).

Now, we have all the tools to define our homogeneous unsupervised DA problem.
In correspondence with~\cite{ganin2016},
we consider a classification problem within an input space \(X\)
with \(L\) possible labels from a set \(Y = {0, \dots, L - 1}\).
The source \(\mathcal{D}_s\) and target \(\mathcal{D}_t\) domains
have different distributions over \(X \times Y\).
From the source and target domains
we have \textit{labelled source sample} \(S\) drawn IID from \(\mathcal{D}_s\)
and \textit{unlabelled target sample} \(T\) drawn IID from \(\mathcal{D}^X_t\) 
(the marginal distribution of \(\mathcal{D}_t\) over \(X\)):

\begin{align}
	S &= \{(\mathbf{x}_i, y_i)\}^n_{i = 1} \sim (\mathcal{D}_s)^n, \\
	T &= \{\mathbf{x}_i\}^N_{i = n + 1} \sim (\mathcal{D}^X_t)^{n'},
\end{align}

where \(N = n + n'\) is the total number of examples
(note that the examples are numbered from 1 to \(N\)).
Concretely, the input space \(X\) is equal to \(\mathbb{R}^{3659}\),
\(y_i \in Y\) which is equal to \(\{0, 1\}\) implying \(L = 2\)
(0 stands for a non-QSO object and 1 for a QSO)
and a vector \(\mathbf{x}_i\) is an astronomical spectrum
(its fluxes in specified wavelengths).

Further categorisation of methods of DA will help us to separate methods based on neural networks.
Csurka in~\cite{csurka2017} divides DA into two categories:
\textit{shallow DA} methods and \textit{deep DA}.
Shallow DA methods are not based on neural networks but rather on statistical theory.
Deep DA methods are based on neural networks augmented for DA.

Furthermore, according to Wang and Deng~\cite{wang2018},
shallow DA methods can be categorised into two classes.
The first class is \textit{instance-based} DA
(the discrepancy is reduced by reweighting the source instances)
and the second is \textit{feature-based} DA
(tries to learn a common shared space in which the discrepancy diminishes).
However, shallow DA methods are not interesting for us
because they do not utilise neural networks directly.
Still, one possibility is to use a neural network as a feature extractor.~\cite{csurka2017}

The following section introduces the other category of deep DA,
which takes advantage of neural networks.

\section{Neural Networks in Domain Adaptation}

Already, Donahue et al. state in the paper on DeCAF~\cite{donahue2014}
that deep neural networks learn more transferable features
that can help with transfer learning.
However, the DeCAF paper also shows
that the performance is still affected by the domain shift.
Therefore, there is enough space for specialised deep architectures for DA.

The group of DA methods using neural networks is called \textit{deep DA}.
Wang \& Deng define it in~\cite{wang2018} as methods that utilise deep neural networks to enhance the performance of DA.
Deep DA architectures can be trained with \textit{backpropagation}.
The idea is that they will learn domain invariant representation
which is also discriminative for a common task.
Such architectures can be trained with backpropagation
learning domain invariant representation discriminative for a common task.
For example, a network is extended with a particular loss, a domain classifier or an autoencoder as we will see next.

Approaches to deep DA were initially divided by Csurka in~\cite{csurka2017} into three categories according to training loss.
Then, Wang and Deng further improve and detail the categorisation into~\cite{wang2018}:

\begin{itemize}
	\item \textit{discrepancy-based} DA fine-tunes the neural network
		with target data to diminish the domain shift;
	\item \textit{adversarial-based} DA encourage domain confusion
		by using discriminators with an adversarial objective; and
	\item \textit{reconstruction-based} DA uses data reconstruction auxiliary task to learn domain invariant features.
\end{itemize}

We summarise the deep DA methods categorisation in the mind map of Figure~\ref{mind_map}.
The mind map also gives further subcategories with some example methods.
Next, we detail the three categories of DA according to the survey by Wang and Deng~\cite{wang2018}.

\begin{figure}
\tikzset{concept/.append style={fill={none}}}
\begin{tikzpicture}
	\path[mindmap, concept color=black]
	node[concept] {Deep DA}
	[clockwise from=60]
	child[concept] {
		node[concept] {Adversarial}
		[clockwise from=75]
		child {node[concept] {generative model}}
		child {
			node[concept] {non-generative model}
			child {node[concept] {DANN}}
			child {node[concept] {ADDA}}
			}
		}
	child[concept] {
		node[concept] {Recon\-struction}
		[clockwise from=30]
		child {node[concept] {adversarial model}}
		child {
			node[concept] {encoder-decoder model}
			child {node[concept] {SDA}}
			child {node[concept] {mSDA}}
			child {node[concept] {DRCN}}
			child {node[concept] {DSN}}
			}
		}
	child[concept] {
		node[concept] {Discrepancy}
		[clockwise from=30]
		child {node[concept] {class criterion}}
		child {
			node[concept] {statistic criterion}
			child {node[concept] {DDC}}
			child {node[concept] {DAN}}
			child {node[concept] {JAN}}
			child {node[concept] {Deep CORAL}}
			}
		child {node[concept] {archi\-tecture criterion}}
		child {node[concept] {geometric criterion}}
		};
\end{tikzpicture}
\caption[Mind map of deep domain adaptation]{
	This mind map present categorisation of deep DA divided as we described it.
	Moreover, we also show concrete deep DA method
	that we have mentioned.
}
\label{mind_map}
\end{figure}

\subsection{Discrepancy-based Deep Domain Adaptation}
\label{discrepancy_da}

The first category is discrepancy-based deep DA methods
that use either labelled or unlabelled target data
to fine-tune a deep neural network to diminish the discrepancy
between the source and target domains.

The discrepancy-based DA methods are subdivided based on \textit{class}, \textit{statistic}, \textit{architecture} and \textit{geometric} criterion by~\cite{wang2018}.
\textit{Class criterion} methods use label information to do DA.
For example, the knowledge is transferred in the form of soft labels or pseudo labels.
\textit{Statistic criterion} methods align some statistic of the source and target distribution.
The most used methods reduce domain shift with the maximum mean discrepancy, correlation alignment or Kullback-Leibler divergence.
Methods with \textit{architecture criterion} adjust the network topology in order to learn more transferable features.
The last subcategory is \textit{geometric criterion} methods
which want to diminish the difference between the source and target distributions based on their geometrical properties.

We choose to focus on the statistic criterion category in this work
because its methods can be used in an unsupervised fashion,
focus straight on the different source and target distributions
and perform very well on two-dimensional images.
We think class criterion subcategory and architecture criterion subcategories are unsuitable.
They focus mostly on supervised DA, and the geometric criterion gives much worst result in comparison to methods based on statistic criterion.

The most successful statistic criterion methods are Deep Domain Confusion (DDC)~\cite{tzeng2014}, Deep Adaptation Network (DAN)~\cite{long2015}, Joint Adaptation Network (JAN)~\cite{long2017} and Deep Correlation Alignment (Deep CORAL)~\cite{sun2016}.
DDC is the fundamental method of the statistic criterion subcategory,
and both DAN and JAN are its extensions.
Deep CORAL is very similar to DDC, but it aligns the second-order statistics.
To keep things simple, we selected to experiment with DDC and Deep CORAL.
We describe the theory behind them next.

\textit{Deep Domain Confusion} (DDC)~\cite{tzeng2014} finds domain invariant representation
while learning to predict class labels.
The intuition behind DDC is that learning representation
that minimises the distance between the source and target distributions
will help a classifier trained on source labelled data
to be directly applied to the target domain.

DDC optimises loss function that includes both prediction error and \textit{domain confusion} loss to learn domain invariant representation.
The invariant representation is achieved by incorporating an \textit{adaptation layer} into a deep \textit{convolutional neural network} (CNN)
with a domain confusion loss computed via \textit{maximum mean discrepancy} (MMD).
MMD is a standard distribution distance metric which is empirically approximated by:

\begin{equation}
	\mathrm{MMD}(S, T) = \left\|
	\frac{1}{n} \sum_{i = 1}^{n} \phi(\mathbf{x}_i) -
	\frac{1}{n'} \sum_{i = n + 1}^{N} \phi(\mathbf{x}_i)
	\right\|,
	\label{maximam_mean_discrepancy}
\end{equation}

where \(\phi: X \to Z)\) is a feature extractor
from the data space \(X\) to a feature space \(Z\)
that operates on both source and target \(\mathbf{x}_i \in X\) data points.

Using the adaptation layer with the domain loss function DDC claims to learn a representation
that is both domain invariant but still offers strong semantic separation enabling to learn a robust label classifier.
Therefore, the goal of DDC is to minimise a loss that incorporates both domain confusion loss and classification loss:

\begin{equation}
	\mathcal{L}_{\mathrm{DDC}} = \mathcal{L}_C(S)
	+ \lambda \mathrm{MMD}^2(S, T),
	\label{ddc_loss}
\end{equation}

where \(\mathcal{L}_C\) stands for classification loss on the labelled source data \(S\) and to control the strength of domain confusion,
DDC introduces a hyperparameter~\(\lambda\)
(\(\lambda = 0.25\) in experiments of DDC).

\tikzstyle{block} = [align=center,draw=black,font=\tiny,rectangle,text centered]
\tikzstyle{data} = [align=center,font=\tiny,text centered]
\tikzstyle{loss} = [align=center,draw=black,font=\tiny,ellipse,text centered]
\begin{figure}
\begin{center}
\begin{tikzpicture}[node distance=2.5cm]
	\node (src) [data] {source\\data};
	\node (trg) [data, below of=src] {target\\data};
	\node (fe1) [block,right of=src] {feature\\extractor};
	\node (fe2) [block,right of=trg] {feature\\extractor};
	\node (al1) [block,right of=fe1] {adaptation\\layer};
	\node (al2) [block,right of=fe2] {adaptation\\layer};
	\node (clf) [block,right of=al1] {classifier};
	\node (loss) [loss,right of=clf] {classification\\loss};
	\node (mmd) [loss,right of=al2] {MMD\\loss};
	\draw [->] (src) -- (fe1);
	\draw [->] (trg) -- (fe2);
	\draw [->] (fe1) -- (al1);
	\draw [->] (fe2) -- (al2);
	\draw [->] (al1) -- (clf);
	\draw [dashed] (fe1) -- (fe2);
	\draw [dashed] (al1) -- (al2);
	\draw (clf) -- (loss);
	\draw (al1) -- (mmd);
	\draw (al2) -- (mmd);
\end{tikzpicture}
\end{center}
\caption{Schema of Deep Domain Confusion}
\end{figure}

In comparison with DDC, \textit{Deep Correlation Alignment} (Deep CORAL) uses \textit{correlation alignment} (CORAL) instead of MMD.
CORAL aligns the second-order statistic of the source and target distributions.
Then, Deep CORAL is a deep neural network
that incorporates a differentiable CORAL loss.

CORAL loss is defined as the distance between covariances of the source and target features extracted from a layer of a deep neural network:

\begin{equation}
	\mathcal{L}_{\mathrm{CORAL}}(S, T) = \frac{1}{4 d^2} \|C(S) - C(T)\|_F^2,
	\label{coral_loss}
\end{equation}

where \(\|\cdot\|_F^2\) is the squared matrix Frobenius norm
and the function \(C\) return a covariance matrix of a given set:

\begin{equation}
	C(D_A) = \frac{1}{|A| - 1} (D_A^\top D_A
	- \frac{1}{|A|} (\mathbf{1}^\top D_A)^\top (\mathbf{1}^\top D_A)),
	\label{deep_coral_loss}
\end{equation}

where \(A\) is a set of examples
that are either the source sample \(S\) or the target sample \(T\)
and \(D_A\) is a design matrix corresponding to the set
that is a matrix where each row is an example.
The \(\mathbf{1}\) is a column vector with all elements equal to 1.

The final composed loss consist of a classification loss \(\mathcal{L}_C\)
and the CORAL loss:

\begin{equation}
	\mathcal{L}_{\mathrm{Deep\,CORAL}}
	= \mathcal{L}_C(S) + \lambda \mathcal{L}_{\mathrm{CORAL}}(S, T),
\end{equation}

where \(\lambda\) is a trade-off hyperparameter similar to the one in the DDC loss in Equation~\ref{ddc_loss}.

Note that Deep CORAL does not introduce an adaptation layer
but uses a layer that is already in the network.
The CORAL loss can be even applied to several layers.

\begin{figure}
\begin{center}
\begin{tikzpicture}[node distance=2.5cm]
	\node (src) [data] {source\\data};
	\node (trg) [data, below of=src] {target\\data};
	\node (fe1) [block,right of=src] {feature\\extractor};
	\node (fe2) [block,right of=trg] {feature\\extractor};
	\node (clf) [block,right of=fe1] {classifier};
	\node (loss) [loss,right of=clf] {classification\\loss};
	\node (coral) [loss,right of=fe2] {CORAL\\loss};
	\draw [->] (src) -- (fe1);
	\draw [->] (trg) -- (fe2);
	\draw [->] (fe1) -- (clf);
	\draw [dashed] (fe1) -- (fe2);
	\draw (clf) -- (loss);
	\draw (fe1) -- (coral);
	\draw (fe2) -- (coral);
\end{tikzpicture}
\end{center}
\caption{Schema of Deep Correlation Alignment}
\end{figure}

\subsection{Adversarial-based Deep Domain Adaptation}
\label{adversarial_da}

Adversarial-based deep DA utilises a domain discriminator
that tries to distinguish whether a sample comes from the source or target domain.
If we can confuse the discriminator,
we will also achieve domain confusion through the adversarial objective.

The adversarial deep DA methods are divided into \textit{generative} and \textit{non-generative} models by~\cite{wang2018}.
\textit{Generative models} create synthetic target data according to source data while keeping source data labels.
These models are usually based on Generative Adversarial Network (GAN)~\cite{goodfellow2014}.
Rather than generating synthetic examples,
\textit{non-generative models} learn via an adversarial objective a feature extractor
that produces domain invariant representation of an example.

We explore the second non-generative subcategory
because we think that proper representation is satisfactory,
and we consider synthetic data generation as overkill for our task.

The fundamental algorithm of non-generative adversarial deep DA is
Domain-Adversarial Neural Network (DANN)~\cite{ganin2016}.
Other methods like Adversarial Discriminative Domain Adaptation (ADDA)~\cite{tzeng2017} built on the idea of DANN.
Therefore, we are convinced that DANN is the right model to try to our problem in our hands.

\textit{Domain-Adversarial Neural Network} (DANN)~\cite{ganin2016} is an adversarial representation learning approach for domain adaptation.
It is based on the idea that useful features for DA
cannot discriminate between source and target domains
while maintaining discriminative properties for a classification task.

DANN combines feature extractor, label predictor and domain classifier is a single architecture
and can be trained with a standard backpropagation learning algorithm.
Because of that, DANN proposes a \textit{gradient reversal layer} (GRL)
that can be incorporated in almost any feed-forward neural network.
Using the GRL DANN jointly optimises feature extractor and two discriminative classifiers.
The first discriminative classifier is a label predictor that predicts classes and the second is a domain classifier
that discriminates between source and target domains.

The feature extractor is trained jointly to minimise a classification loss
and maximise the loss of the domain classifier.
Thus, domain classifier and feature extractor are learning in adversarial fashion to encourage domain invariant features.

To define the learning objective let
\(G_f(\cdot; \theta_f)\) be the neural network feature extractor with parameters \(\theta_f\),
\(G_y(\cdot; \theta_y)\) be the label predictor with parameters \(\theta_y\)
that takes features from \(G_f\) as inputs and output class probabilities,
and \(G_d(\cdot; \theta_d)\) be the domain classifier with parameters \(\theta_d\). 
Training DANN is optimising prediction loss and domain loss:

\begin{align}
	E(\theta_f, \theta_y, \theta_d) &= \frac{1}{n} \sum^{n}_{i = 1} \mathcal{L}_y(G_y(G_f(\mathbf{x}_i; \theta_f), \theta_y), y_i) \nonumber \\
	&\qquad {} - \lambda \left(\frac{1}{n} \sum^{n}_{i = 1} \mathcal{L}_d(G_d(G_f(\mathbf{x}_i; \theta_f), \theta_d), d_i) \right. \nonumber \\
	&\qquad \left. {} + \frac{1}{n'} \sum^{N}_{i = n + 1} \mathcal{L}_d(G_d(G_f(\mathbf{x}_i; \theta_f), \theta_d), d_i)\right)
\end{align}

by finding the saddle point \(\hat{\theta}_f\), \(\hat{\theta}_y\), \(\hat{\theta}_d\) that satisfy:

\begin{align}
	(\hat{\theta}_f, \hat{\theta}_y)
	&= \operatorname*{arg\,min}_{\theta_f, \theta_y} E(\theta_f, \theta_y, \hat{\theta}_d),\\
	\hat{\theta}_d
	&= \operatorname*{arg\,max}_{\theta_d} E(\hat{\theta}_f, \hat{\theta}_y, \theta_d).
\end{align}

where \(\mathcal{L}_y\) is a classification loss,
\(\mathcal{L}_d\) is a domain loss,
\(\lambda\) is a trade-off hyperparameter
and \(d_i\) is a binary variable (a domain label):

\begin{equation}
	d_i =
	\begin{cases}
		0 & \quad \text{if } i \in \{1, \dots, n\}, \\
		1 & \quad \text{if } i \in \{n + 1, \dots, N\}.
	\end{cases}
\end{equation}

The DANN paper shows that saddle points can be found using gradient updates
similar to \textit{stochastic gradient descent} (SGD):

\begin{align}
	\theta_f &\gets \theta_f - \mu \left(
	\frac{\partial \mathcal{L}_y^i}{\partial \theta_f}
	- \lambda \frac{\partial \mathcal{L}_d^i}{\partial \theta_f}
	\right),
	\label{feature_parameters_update} \\
	\theta_y &\gets \theta_y - \mu
	\frac{\partial \mathcal{L}_y^i}{\partial \theta_y}, \\
	\theta_d &\gets \theta_d - \mu \lambda
	\frac{\partial \mathcal{L}_d^i}{\partial \theta_d}.
\end{align}

However, the update in Equation~\ref{feature_parameters_update} has subtraction in it instead of addition.
DANN overcomes the substruction by incorporating the GRL \(\mathcal{R}(\mathbf{z})\) between the feature extractor and domain classifier.
The GRL has no parameters, and during forward propagation, the GRL acts as identity:

\begin{equation}
	\mathcal{R}(\mathbf{z}) = \mathbf{z}.
\end{equation}

However, in backpropagation, it negates the gradient:

\begin{equation}
	\frac{d \mathcal{R}}{d \mathbf{z}} = -\mathbf{I},
\end{equation}

where \(\mathbf{I}\) is the identity matrix,
and \(\mathbf{z}\) is the representation produced by the feature extractor
\(G_f(\cdot, \theta_f)\).
Now, DANN can seamlessly work with SGD
because the objective to be optimised with gradient descent is transformed into:

\begin{align}
	E(\theta_f, \theta_y, \theta_d) &= \frac{1}{n} \sum^{n}_{i = 1} \mathcal{L}_y(G_y(G_f(\mathbf{x}_i; \theta_f), \theta_y), y_i) \nonumber \\
	&\qquad {} - \lambda \left(\frac{1}{n} \sum^{n}_{i = 1} \mathcal{L}_d(G_d(\mathcal{R}(G_f(\mathbf{x}_i; \theta_f)), \theta_d), d_i) \right. \nonumber \\
	&\qquad \left. {} + \frac{1}{n'} \sum^{N}_{i = n + 1} \mathcal{L}_d(G_d(\mathcal{R}(G_f(\mathbf{x}_i; \theta_f)), \theta_d), d_i)\right).
	\label{dann_loss}
\end{align}

The GRL changes the update~\ref{feature_parameters_update}
to version fully compatible with SGD:

\begin{equation}
	\theta_f \gets \theta_f - \mu \left(
	\frac{\partial \mathcal{L}_y^i}{\partial \theta_f}
	+ \lambda \frac{\partial \mathcal{L}_d^i}{\partial \theta_f}
	\right).
\end{equation}

\begin{figure}
\begin{center}
\begin{tikzpicture}[node distance=2.5cm]
	\node (src) [data] {source\\data};
	\node (all) [data, below of=src] {all\\data};
	\node (fe1) [block,right of=src] {feature\\extractor};
	\node (fe2) [block,right of=all] {feature\\extractor};
	\node (clf) [block,right of=fe1] {label\\predictor};
	\node (dom) [block,right of=fe2] {domain\\classifier};
	\node (clf_loss) [loss,right of=clf] {classification\\loss};
	\node (dom_loss) [loss,right of=dom] {domain\\loss};
	\draw [->] (src) -- (fe1);
	\draw [->] (all) -- (fe2);
	\draw [->] (fe1) -- (clf);
	\draw [->] (fe2) -- (dom);
	\draw [dashed] (fe1) -- (fe2);
	\draw (clf) -- (clf_loss);
	\draw (dom) -- (dom_loss);
\end{tikzpicture}
\end{center}
\caption{Schema of Domain-Adversarial Neural Network}
\end{figure}

\subsection{Reconstruction-based Deep Domain Adaptation}
\label{reconstruction_da}

The last group of methods is based on a data reconstruction auxiliary task.
The reconstructor forces to find a shared representation of a source and target domains.

According to~\cite{wang2018}, subcategories are \textit{encoder-decoder} and
\textit{adversarial} reconstruction.
The more uncomplicated \textit{encoder-decoder} category exploits stacked autoencoders~\cite{vincent2008} or stacked convolutional autoencoders~\cite{masci2011}
to do the reconstruction task.
On the other hand, the methods based on \textit{adversarial reconstruction} use cyclic mapping obtained via a GAN discriminator~\cite{goodfellow2014}.

Furthermore, we explore the \textit{encoder-decoder} methods that are a good fit for our problem
because they are not that complicated as GAN-based method of the second subcategory.

It all started with Stacked Denoising Autoencoder (SDA)~\cite{glorot2011}
and it extension marginalised SDA (mSDA)~\cite{chen2012} for DA on text sentiment analysis data.
While SDA and mSDA are base on fully-connected networks,
Deep Reconstruction-Classification Network (DRCN)~\cite{ghifary2016}
uses stacked convolutional autoencoder for the reconstruction task on images.
Moreover, Domain Separation Networks (DSN)~\cite{bousmalis2016} is based on the same idea as DRCN.
However, it uses three separate encoders to model shared representation
and also private specific representations of the source and target data.
We choose to experiment with DRCN
because it is designed for image data while being more straightforward than DSN.

\textit{Deep Reconstruction-Classification Network} (DRCN)~\cite{ghifary2016} is a CNN that learn both supervised source labelled classification and unsupervised target data reconstruction.
The encoder is shared between both task, but decoding parameters are separate.
The data reconstruction task is an auxiliary task supposed to help to learn good feature representation beneficial for DA scenario.
The intuition behind DRCN is
that good representation for DA should capture both the properties for classification and data structure
(reconstruct well the target domain).

DRCN is composed of a label predictor for classification
and a convolutional autoencoder for target data reconstruction.
Let define \(F_c: X \to Y\) as the label predictor
and \(F_r: X \to X\) is the data reconstructor.
The two functions are composed of three components:

\begin{itemize}
	\item an encoder feature mapping \(G_e: X \to Z\);
	\item a decoder \(G_d: Z \to X\); and
	\item a classificator \(G_l: Z \to Y\);
\end{itemize}

where \(Z\) is a latent feature space to which DRCN encodes data.
Given the above component,
the classification pipeline is \(F_c(\cdot; \theta_c) = G_l(G_e(\cdot; \theta_e); \theta_l)\),
and the reconstruction pipeline is \(F_r(\cdot; \theta_r) = G_d(G_e(\cdot; \theta_e); \theta_d)\)
where \(\theta_c = \{\theta_e, \theta_l\}\) are parameters of the classificator
and \(\theta_r = \{\theta_d, \theta_e\}\) are parameters of the reconstructor.
Note that \(\theta_e\) is shared between the label predictor and the autoencoder.

The model is jointly optimised for classification and reconstruction tasks.
Therefore, the learning objective of DRCN contains classification and reconstruction loss, respectively:

\begin{align}
	\mathcal{L}_c(S) &= \sum_{i = 1}^{n}
	l_c(F_c(\mathbf{x}_i; \theta_c), y_i),
	\label{drcn_classification_loss} \\
	\mathcal{L}_r(T) &= \sum_{i = n + 1}^{N}
	l_r(F_r(\mathbf{x}_i; \theta_r), \mathbf{x}_i),
	\label{drcn_reconstruction_loss}
\end{align}

where \(l_c\) is a form of classification loss
and \(l_r\) is a reconstruction loss, for example, the squared loss:

\begin{equation}
	l_r = \|\mathbf{x}_i - F_r(\mathbf{x}_i)\|_2^2.
\end{equation}

By combining the terms~\ref{drcn_classification_loss} and~\ref{drcn_reconstruction_loss},
DRCN aims to minimise the following objective:

\begin{equation}
	\mathcal{L}_{\mathrm{DRCN}}
	= \lambda \mathcal{L}_c(S) + (1 - \lambda) \mathcal{L}_r(T),
	\label{drcn_loss}
\end{equation}

where \(\lambda \in [0, 1]\) is a hyperparameter of the trade-off between the two loss functions.
The objective~\ref{drcn_loss} can be optimised with SGD.

\begin{figure}
\begin{center}
\begin{tikzpicture}[node distance=2.5cm]
	\node (src) [data] {source\\data};
	\node (trg) [data, below of=src] {target\\data};
	\node (enc1) [block,right of=src] {encoder};
	\node (enc2) [block,right of=trg] {encoder};
	\node (clf) [block,right of=enc1] {classifier};
	\node (dec) [block,right of=enc2] {decoder};
	\node (clf_loss) [loss,right of=clf] {classification\\loss};
	\node (rec_loss) [loss,right of=dec] {reconstruction\\loss};
	\draw [->] (src) -- (enc1);
	\draw [->] (trg) -- (enc2);
	\draw [->] (enc1) -- (clf);
	\draw [->] (enc2) -- (dec);
	\draw [dashed] (enc1) -- (enc2);
	\draw (clf) -- (clf_loss);
	\draw (dec) -- (rec_loss);
\end{tikzpicture}
\end{center}
\caption{Schema of Deep Reconstruction-Classification Network}
\end{figure}

\section{Previous Applications of Domain Adaptation in Astronomy}
\label{da_astronomy}

As we have shown in Section~\ref{large_spec_surveys},
DA is of great interest to astronomers
because of different instruments, measurements and observation distribution.
Therefore, we survey the current state of DA in astronomical applications in this section.

If we have a common set of observed stars in both archives (supervised DA),
then we can map them and learn a transfer function.
Ho et al.~\cite{ho2017} did exactly that
because they found a common set of 9\,952 spectra in both APOGEE and LAMOST archive.
Using the common set, they trained the Cannon method~\cite{ness2015},
and they used the model to transfer some stellar physical parameters from APOGEE to LAMOST.

In the case, when there is no common set (unsupervised DA)
Gupta et al.~\cite{gupta2016} experimented
with \textit{subspace alignment}~\cite{fernando2014}
and \textit{kernel mean matching}~\cite{gretton2009}
followed by \textit{active learning}~\cite{settles2009}.
In the case of subspace alignment,
the negative transfer occurred
while the kernel mean matching seems very promising in the task of supernova classification.
However, they observed that those shallow methods
(subspace alignment and kernel mean matching) are not sufficient on their own,
and the active learning phase is crucial.
Nevertheless, active learning requires human expert interaction,
so it is not automatic and depends on domain knowledge.

Then, Vilalta et al.~\cite{vilalta2018} extended the work of Gupta et al.~\cite{gupta2016}.
Vilalta et al. used a supervised \textit{maximum a~posteriori} (MAP) approach
to learning a~prior on the model parameters from a spectroscopic source domain
and then use this prior distribution to learn a model in a photometric target domain.
Concretely, Vilalta et al. put a prior on the number of layers of a neural network
and then used active learning.

Richards et al.~\cite{richards2011} faced a similar situation, as Gupta et al.
Richards et al. introduce the problem as sample selection bias~\cite{shimodaira2000} or covariate shift~\cite{heckman1979}
when different distributions generate the source and target data.
That is precisely the problem we have defined as DA.
Richards et al. experimented with random forest in combination with three DA methods:
\textit{importance weighting}~\cite{shimodaira2000},
\textit{co-training}~\cite{blum1998}
and \textit{active learning}~\cite{settles2009}.
Active learning works best while importance weighting and co-training achieve negative transfer.

It seems that active learning is crucial
to achieving good result on astronomical data when using shallow DA methods.
We speculate that it is the nature of scientific data
that makes shallow DA method unusable on its own.
Next, we describe a supervised deep DA  approach
that shown to work well on astronomical data.
Therefore, we think neural network DA methods should be promising in astronomy.

The term transfer learning has been recently used in the context of deep learning.
However, transfer learning in the context of deep learning means something more concrete than what we defined as transfer learning previously.
Transfer learning in the context of deep learning is the specific situation
when a pre-trained deep neural network model is taken,
and its last layers are retrained with the target domain data.

Ackermann et al.~\cite{ackermann2018} employed a deep CNN
with the transfer learning approach
in the context of deep learning to detect galaxy merges
from two-dimensional images.
They took the pre-trained Xception CNN~\cite{chollet2017}
and fine-tuned its last layers with images of galaxy merger labelled
in a citizen science Galaxy Zoo project~\cite{lintott2010}.
This transfer learning approach allowed them to lower the best error rate so far by 15\%.

Next application of deep DA method in astronomy is \textit{Deep Variational Transfer} (DVT)~\cite{belhaj2018}.
DVT is a semisupervised model based on variational autoencoders~\cite{kingma2014a} and mixture models.
They encode the source and target data into a shared latent space
and identify clusters with the labelled target data.
They experimented with light curves (time series of light intensity) of stars.

This section shows that applications of deep DA in astronomy are minimal.
Therefore, our work will be almost the first to explore the ideas
of deep DA in astronomy with huge potential to discover
either new tool for astronomy or a new challenge for deep DA.

\chap Machine Learning

\sec Transfer Learning

In~\cite[Ackermann2018] transfer learning is used as {\em regularization}.
Their network for classification of galaxy mergers is pretrained with ImageNet
dataset.

\sec Deep Learning

Deep learning survey according to~\cite[Goodfellow2016].

\sec Active Learning

This section is summary of~\cite[Settles2009]. The idea of {\em active
learning} is that a machine learning algorithm can achieve better accuracy
with fewer training examples if it is allowed to choose the data from which
it learns. An active learner my pose {\em queries} for data instances to be
labeled by an {\em oracle} (a human expert).

\secc Scenarios

There are three problem scenarios in which the learning algorithm may ask
queries {\em membership query synthesis}, {\em stream-based selective sampling}
and {\em pool-based sampling}.

All these scenarios assume that queries take the form of unlabeled examples
to be labeled by the oracle.

In {\bf membership query synthesis} the learner may request labeling of any
unlabeled example in the input space, including synthetically generated
examples, rather than sampling from underlying distribution. Query synthesis
is reasonable for many problems but may produce examples without semantic
meaning that are awkward to label if the oracle is a human annotator.

{\bf Stream-based selective sampling} assumes that obtaining an unlabeled
example is inexpensive, so it first sampled the underlying distribution
and that it decides whether or not to request its label.  The decision whether
or not to query an example can be based on evaluation of some informativeness
measure and setting threshold or other query strategy.

{\bf Pool-based sampling} is optimal if there large collection of unlabeled
data can be gathered at once. It assumes a small set of labeled data $\cal L$
and a large pool of unlabeled data $\cal U$. Queries are selectively drawn
from the pool according to an informativeness measure used to evaluate all
examples in the pool.

The main difference between stream-base and pool-based active learning is
that the stream-based process the data sequentially and make the decisions
individually while the pool-based ranks the entire collection before
selecting the best query.

\secc Query Strategy Framework

All active learning scenarios involve evaluating the informativeness
of unlabeled example. Here are some proposed ways of formulating such query
strategies:

\begitems
* passive sampling,
* uncertainty sampling,
* query-by-committee,
* expected model change,
* expected error reduction,
* variance reduction and
* density-weighted methods.
\enditems

The simplest is {\em passive sampling} which selects examples at random.

The most commonly used strategy is {\em uncertainty sampling} that queries
examples about which it is least certain how to label. For example
{\em Shannon's entropy} can be used.

A more theoretically-motivated approach is the {\em query-by-committee}
(\glref{QBC}) algorithm. The \glref{QBC} involves maintaining a committee of
${\cal C} = \{\theta^{(1)}, \dots, \theta^{(C)}\}$ of $C$ models
which vote on the labeling query candidates. The most informative query is
the example they most disagree on (can be measured using
Kullback-Leibler divergence).

{\em Expected model change} query strategy framework is based on
decision-theoretic approach, selecting the example with biggest impact to
the current model if its label is known.

Similar idea of {\em expected error reduction} is to choose an example based
on how much the generalization error is likely to be reduced. Related
method is {\em variance reduction} which tries to reduce generalization error
indirectly by minimizing output variance.

Lastly the survey present {\em density-weighted methods} which model the input
distribution explicitly during query selection to find informative instances
which are both uncertain and representative (inhabit dense regions of the input
space).

\secc Related Research Areas

Active learning is very similar to
{\em semi-supervised learning}~\cite[Zhu2005], but while
semi-supervised learning methods exploit the area they are most confident
about, the active learning methods attempt to explore the uncertain aspects.

Other similar area to active learning is
{\em reinforcement learning}~\cite[Sutton2018] in which learner interacts
with an environment via actions and tries to find optimal policy with respect
to rewards. The relationship to active learning is that, in order to perform
well, the learner must be proactive.

\sec Machine Learning in Astronomy

\secc Active Learning to Overcome Sample Selection Bias

In~\cite[Richards2012] authors use active learning to overcome the {\em sample
selection bias} (in astronomy the distributions of training and testing
data are usually different). They aim to classify variable
stars from light curves from archive data different that the data used for
learning the classifier using {\em importance weighting}, {\em co-training}
and {\em active learning}. Result is that active learning perform best on
their astronomical data.

\secc Transfer Learning in Astronomy: A New Machine-Learning Paradigm

In~\cite[Vilalta2017] Vilalta studies usage of transfer learning in astronomy.
Common machine learning assumption is that a training distribution is static
but there is wide range of application which do not follow this assumption.
For example there is a lot of information known about nearby objects but
as technology improves it is possible to observe more distant objects which come
from very different distribution because distant objects can be observed only
if they are luminous enough.

A source dataset $T_s = \{({\bf x}, y)\}$ where ${\bf x} \in {\cal X}$ is
a feature vector and $y \in {\cal Y}$ is a class. A source dataset produces
a predictive model $f_s({\bf x})$ which needs some adaptation to perform better
on a new distribution. Examples in $T_s$ are drawn from a joint
distribution $P_s({\bf x}, y)$. Then there is the marginal distribution
$P_s({\bf x})$ and the posterior distribution $P_s(y | {\bf x})$. The target
dataset $T_t$ corresponds to a new application similar to the source dataset.
Transfer learning helps to exploit previous knowledge acquired in $f_s({\bf x})$
so that classifier $f_t({\bf x})$ does not need to be created from scratch.

In homogenous transfer learning the feature representations are the same
${\cal X}_s = {\cal X}_t$ otherwise it is called heterogeous. In homogenous
transfer learning there can be differences in marginal distributions
$P_s({\bf x}) \neq P_t({\bf x})$, in posterior distributions
$P_s(y | {\bf x}) \neq P_t(y | {\bf x})$ or in both.

There are different approches to transfer learning. One is
{\em covariance-shift} where the model is built on a new source
distribution which is weighted to be similar to target distribution.
Another approach is to adapt model parameter in some way to perform better
on a target distribution.

The paper then describes application of transfer learning where source domain
is well-labeled spectroscopic data and target domain is data from
a photometric survey. It uses PCA and other methods to map the to dataset
to a common space.

{\em Negative transfer} is a phenomenon where the use of transfer learning
leads to loss of performance.

Finaly, during experiments, when the performance of transfer learning is not
that good, active learning is introduces which bring significant improvement
in performance.

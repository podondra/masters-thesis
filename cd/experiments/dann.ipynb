{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from qso.utils import init_weights, load_ds, predict\n",
    "from qso.models import DANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_file = Path(\"data\") / \"dataset.hdf5\"\n",
    "bs = 64\n",
    "bs_eval = 2048\n",
    "\n",
    "src_ds = load_ds(ds_file, \"sdss\")\n",
    "src_dl = DataLoader(src_ds, batch_size=bs, shuffle=True)\n",
    "src_dl_eval = DataLoader(src_ds, batch_size=bs_eval)\n",
    "src_dl_va = DataLoader(load_ds(ds_file, \"sdss\", va=True), batch_size=bs_eval)\n",
    "trg_dl = DataLoader(load_ds(ds_file, \"lamost\"), batch_size=bs, shuffle=True)\n",
    "trg_dl_va = DataLoader(load_ds(ds_file, \"lamost\", va=True), batch_size=bs_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(-1, 1, num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\")\n",
    "model = DANN().to(dev)\n",
    "dom_predictor = lambda x: model.domain_classifier(model.feature_extractor(x), None)\n",
    "model.apply(init_weights)\n",
    "dom_criterion = nn.BCEWithLogitsLoss()\n",
    "pred_criterion = nn.BCEWithLogitsLoss()\n",
    "lr0 = 0.01\n",
    "opt = optim.SGD(model.parameters(), lr=lr0, momentum=0.9)\n",
    "\n",
    "writer = SummaryWriter(comment=\"_dann\")\n",
    "\n",
    "alpha = 10\n",
    "beta = 0.75\n",
    "gamma = 10\n",
    "epochs = 20\n",
    "iters = epochs * min(len(src_dl), len(trg_dl))\n",
    "iterator = count(1)\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for i, (src_xb, src_yb), (trg_xb, _) in zip(iterator, src_dl, trg_dl):        \n",
    "        src_xb, src_yb = src_xb.to(dev), src_yb.to(dev)\n",
    "        trg_xb = trg_xb.to(dev)\n",
    "        xb = torch.cat([src_xb, trg_xb])\n",
    "        dom_yb = torch.cat([torch.zeros(src_xb.size(0)), torch.ones(trg_xb.size(0))]).to(dev)\n",
    "\n",
    "        # update hyperparameters\n",
    "        p = (i - 1) / (iters - 1)\n",
    "        lam = (2 / (1 + np.exp(-gamma * p))) - 1\n",
    "        lr = lr0 / ((1 + alpha * p) ** beta)\n",
    "        for param_group in opt.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "        fb = model.feature_extractor(xb)\n",
    "        dom_pred = model.domain_classifier(fb, lam)\n",
    "        pred = model.label_predictor(fb[:src_xb.size(0)])\n",
    "\n",
    "        dom_loss = dom_criterion(dom_pred, dom_yb.unsqueeze(-1))\n",
    "        pred_loss = pred_criterion(pred, src_yb.unsqueeze(-1))\n",
    "        loss = pred_loss + dom_loss\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        src_trues, src_preds = predict(model, src_dl_eval, dev)\n",
    "        src_trues_va, src_preds_va = predict(model, src_dl_va, dev)\n",
    "        trg_trues_va, trg_preds_va = predict(model, trg_dl_va, dev)\n",
    "        _, src_doms = predict(dom_predictor, src_dl_va, dev)\n",
    "        _, trg_doms = predict(dom_predictor, trg_dl_va, dev)\n",
    "\n",
    "    # log statistics\n",
    "    writer.add_scalars(\"loss\", {\"training\": pred_criterion(src_preds, src_trues),\n",
    "                                \"validation\": pred_criterion(src_preds_va, src_trues_va)}, epoch)\n",
    "    writer.add_scalars(\"f1\", {\"source\": f1_score(src_trues_va.bool(), src_preds_va > 0),\n",
    "                              \"target\": f1_score(trg_trues_va.bool(), trg_preds_va > 0)}, epoch)\n",
    "    doms_true = torch.cat([torch.zeros(src_doms.size(0), dtype=torch.bool),\n",
    "                           torch.ones(trg_doms.size(0), dtype=torch.bool)])\n",
    "    doms_pred = torch.cat([src_doms > 0, trg_doms > 0])\n",
    "    writer.add_scalars(\"accuracy\", {\"both\": accuracy_score(doms_true, doms_pred),\n",
    "                                    \"source\": (src_doms < 0).float().mean().item(),\n",
    "                                    \"target\": (trg_doms > 0).float().mean().item()}, epoch)\n",
    "\n",
    "torch.save(model.state_dict(), str(Path(\"models\") / \"dann.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
